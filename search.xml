<?xml version="1.0" encoding="utf-8"?>
<search>
  
    
    <entry>
      <title><![CDATA[composer整合github实现自动推送项目到packagist.org]]></title>
      <url>%2F2017%2F03%2F28%2Fcomposer%E6%95%B4%E5%90%88github%E5%AE%9E%E7%8E%B0%E8%87%AA%E5%8A%A8%E6%8E%A8%E9%80%81%E9%A1%B9%E7%9B%AE%E5%88%B0packagist-org%2F</url>
      <content type="text"><![CDATA[概念 Composer PHP包管理工具（例如：Ruby的RubyGems, Nodejs的npm, Python的pip) Packagist.org composer 镜像 中国镜像地址：https://pkg.phpcomposer.com Github GitHub 是一个面向开源及私有软件项目的托管平台，因为只支持 Git 作为唯一的版本库格式进行托管，故名 GitHub。 安装系统环境System：OS X EI Capitan (版本10.11.6) Composer 安装Composer之前请确保安装了PHP 12345678910$ curl -sS https://getcomposer.org/installer | php # 下载composer&gt; #!/usr/bin/env phpAll settings correct for using ComposerDownloading...&gt;&gt;Composer successfully installed to: /root/composer.phar&gt;Use it: php composer.phar # 会下载一个composer.phar文件$ mv composer.phar /usr/local/bin/composer$ composer -VComposer version 1.1.1 # 安装成功 如果下载不成功，可以 download composer.phar 提交composer.json 到github 在GitHub创建项目 默认你已经有Github账号，并且懂得git基本操作 克隆项目到本地并且建立composer.json 123456789101112131415161718192021222324252627282930313233343536373839404142$ git clone https://github.com/lijianhua/demo.git demo # 克隆项目$ cd demo$ composer init # 生成composer.json文件 Welcome to the Composer config generator This command will guide you through creating your composer.json config.Package name (&lt;vendor&gt;/&lt;name&gt;) [root/demo]:lijianhua/demo# 设置你的package 名字Description []: This a demo for build composer packagist .# 描述Author [Li Jianhua &lt;lijianhua_oop@163.com&gt;, n to skip]: # 作者信息Minimum Stability []: dev # 稳定版本Package Type (e.g. library, project, metapackage, composer-plugin) []: project # package 类型License []: MIT # 开源协议 有五种：(BSD，Apache，GPL，LGPL，MIT)Define your dependencies.Would you like to define your dependencies (require) interactively [yes]? no # 是否有依赖于别的package, 这里选择no， 如果选yes会问以来名字和版本等&#123; "name": "lijianhua/demo", "description": "demo", "type": "project", "license": "MIT", "authors": [ &#123; "name": "Li Jianhua", "email": "lijianhua_oop@163.com" &#125; ], "minimum-stability": "dev", "require": &#123;&#125; &#125; Do you confirm generation [yes]? yesWould you like the vendor directory added to your .gitignore [yes]? yes$ lscomposer.json $ git add composer.json$ git commit -am 'first commit'$ git push -u origin master 现在你的项目就创建完毕了，并且提交到了Github上 建立GitHub和packagist.org的关联 访问 packagist.org，并登陆，可以选择GitHub账号登陆,点击Submit 复制Github地址，点击check后如果没有重名点击submit 提示我已经创建，如果你第一次提示已经被创建，修改composer.json里的name 并且提交到GitHub，重新验证直到成功为止 提交成功后，出现如下页面 现在就可以通过命令来创建项目 1234$ composer create-project lijianhua/demo a dev-master --prefer-dist $ cd a$ lscomposer.json # 代码已经成功创建到本地， 接下来我们回到package 的创建目录：demo 1234567891011121314$ cd demo$ vim index.php # 创建index.php 添加如下代码$ cat index.php&lt;?php echo '成功';?&gt;$ git add$ git commit -am 'add index'$ git push origin master # 此时查看GitHub，看见index.php已经提交$ cd .. # 退出demo目录$ composer create-project lijianhua/demo a2 dev-master --prefer-dist # 创建项目a2$ cd a2$ lscomposer.json # 发现没有index.php 这时我们手动点击下图的update 1234$ composer create-project lijianhua/demo a3 dev-master --prefer-dist # 3$ cd a3$ lscomposer.json index.php # 这时候index.php已经提交到packagist了 当然上述方法太过麻烦，下面我们展示自动推送 GitHub自动推送项目到packagist 在Github 项目页点击setting，在出现的页面选择 services 点击add service, 在出现的框内选择packagist并添加 填写你的user 就是你的github用户名，Domain 就是 packagist的地址 Token 在packagist 官网点击Profile-&gt;Show API Token，辅助内容到上图，保存就可以了。 现在更新你demo后就会自动提交到packagist上，由于延迟等原因每次提交可能需要一点时间大概1分钟左右。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[开源实时日志分析ELK平台实践]]></title>
      <url>%2F2017%2F03%2F26%2F%E5%BC%80%E6%BA%90%E5%AE%9E%E6%97%B6%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90ELK%E5%B9%B3%E5%8F%B0%E5%AE%9E%E8%B7%B5%2F</url>
      <content type="text"><![CDATA[周末参加活动看见别人分享的MONOLOG优化及打造ELK友好的日志格式 ，会后了解了下ELK，看见网上最新的资料比较少，大多是过去的版本，不同版本的配置有些许区别，所以花了一点时间学习了下，记录下来分享一下，希望对你有用，话不多说，下面开始。 ELK是什么？ ELK由ElasticSearch、Logstash和Kiabana三个开源工具组成，作用是集中化管理日志，而且对于日志的统计、检索、排序等操作有很好的支持 概述 ELK 官方网址 https://www.elastic.co/products Elasticsearch是个开源分布式搜索引擎，它的特点有：分布式，零配置，自动发现，索引自动分片，索引副本机制，restful风格接口，多数据源，自动搜索负载等。 Logstash是一个完全开源的工具，他可以对你的日志进行收集、分析，并将其存储供以后使用（如，搜索)。 Kibana 也是一个开源和免费的工具，他Kibana可以为 Logstash 和 ElasticSearch 提供的日志分析友好的 Web 界面，可以帮助您汇总、分析和搜索重要数据日志。 为什么用ELK?日志主要包括系统日志、应用程序日志和安全日志。系统运维和开发人员可以通过日志了解服务器软硬件信息、检查配置过程中的错误及错误发生的原因。经常分析日志可以了解服务器的负荷，性能安全性，从而及时采取措施纠正错误。 通常，日志被分散的储存不同的设备上。如果你管理数十上百台服务器，你还在使用依次登录每台机器的传统方法查阅日志。这样是不是感觉很繁琐和效率低下。当务之急我们使用集中化的日志管理，例如：开源的syslog，将所有服务器上的日志收集汇总。 集中化管理日志后，日志的统计和检索又成为一件比较麻烦的事情，一般我们使用grep、awk和wc等Linux命令能实现检索和统计，但是对于要求更高的查询、排序和统计等要求和庞大的机器数量依然使用这样的方法难免有点力不从心。ELK完美的解决了如上问题，因此它是开发人员和运维人员不错的选择。以上内容来源网络 ELK安装和配置系统环境System：OS X EI Capitan (版本10.11.6) ElasticSearch: 5.2.2 Logstash: 5.2.2 Kibana: 5.2.2 Java：java version “1.8.0_121” 由于Logstash的运行依赖于Java环境， 推荐使用最新版本的Java。因为我们只需要Java的运行环境，所以可以只安装JRE，不过这里我依然使用JDK。 建议使用同一时期最细版本的ELK 安装 Java jdk 地址：JDK 选择Accept License Agreement，选择你系统对应版本，这里我选择jdk-8u121-macosx-x64.dmg) 傻瓜版 可能遇见问题，点击安装后一直显示正在验证，重启解决 安装成功后，环境变量设置 JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk1.8.0_121.jdk/Contents/Home PATH=$JAVA_HOME/bin:$PATH CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar export JAVA_HOME, PATH, CLASSPATH 把环境变量加入你用的shell，我的的zsh，例如vim .zshrc 接下来验证JAVA是否安装成功 1234$ java -versionjava version "1.8.0_121"Java(TM) SE Runtime Environment (build 1.8.0_121-b13)Java HotSpot(TM) 64-Bit Server VM (build 25.121-b13, mixed mode) Logstash 地址：https://www.elastic.co/downloads， 我们可以看到ELK三个产品 点击 Download，选择你系统对应的文件下载，这里我选择的tar.gz 下载完成后解压到你指定的目录 123456789$ tar -zxf logstash-5.2.2.tar -C /usr/local/$ /usr/local/logstash-5.2.2/bin/logstash -e "input &#123;stdin&#123;&#125;&#125; output &#123;stdout&#123;&#125;&#125;" #通过-e参数指定logstash的配置信息，用于快速测试，直接输出到屏幕Sending Logstash's logs to /usr/local/logstash-5.2.2/logs which is now configured via log4j2.properties[2017-03-26T21:09:36,336][INFO ][logstash.pipeline ] Starting pipeline &#123;"id"=&gt;"main", "pipeline.workers"=&gt;4, "pipeline.batch.size"=&gt;125, "pipeline.batch.delay"=&gt;5, "pipeline.max_inflight"=&gt;500&#125;[2017-03-26T21:09:36,371][INFO ][logstash.pipeline ] Pipeline main startedThe stdin plugin is now waiting for input:[2017-03-26T21:09:36,512][INFO ][logstash.agent ] Successfully started Logstash API endpoint &#123;:port=&gt;9600&#125;my name is lijianhua # 手动输入回车等待几秒返回结果2017-03-26T13:09:49.174Z Gubler.lan my name is lijianhua 以上logstash 安装成功了 logstash有两个常用的参数 -e :指定logstash的配置信息，可以用于快速测试 -f :指定logstash的配置文件；可以用于生产环境 Elasticsearch 点击 Download，选择你系统对应的文件下载，这里我选择的tar 下载完成后解压到你指定的目录 123456789$ tar -zxf elasticsearch-5.2.2.tar -C /usr/local/$ vim /usr/local/elasticsearch-1.7.2/config/elasticsearch.yml # 修改配置信息，去掉'#'号cluster.name=elasticsearch配置的集群名称，默认是elasticsearch，es服务会通过广播方式自动连接在同一网段下的es服务，通过多播方式进行通信，同一网段下可以有多个集群，通过集群名称这个属性来区分不同的集群。node.name=node0当前配置所在机器的节点名，你不设置就默认随机指定一个name列表中名字，该name列表在es的jar包中config文件夹里name.txt文件中，其中有很多作者添加的有趣名字network.port=9200设置对外服务的http端口，默认为9200。$ /usr/local/elasticsearch-5.2.2/bin/elasticsearch 更多配置信息参考 123456789101112131415浏览器输入：http://localhost:9200，输出如下信息：&#123; &quot;name&quot; : &quot;node-1&quot;, &quot;cluster_name&quot; : &quot;test-elasticsearch&quot;, &quot;cluster_uuid&quot; : &quot;kimjdc71S6W54DXaB3Fl0A&quot;, &quot;version&quot; : &#123; &quot;number&quot; : &quot;5.2.2&quot;, &quot;build_hash&quot; : &quot;f9d9b74&quot;, &quot;build_date&quot; : &quot;2017-02-24T17:26:45.835Z&quot;, &quot;build_snapshot&quot; : false, &quot;lucene_version&quot; : &quot;6.4.1&quot; &#125;, &quot;tagline&quot; : &quot;You Know, for Search&quot;&#125;安装成功 安装Elasticsearch HEAD插件 elasticsearch-head是一个elasticsearch的集群管理工具，它是完全由HTML5编写的独立网页程序，你可以通过插件把它集成到ES 网上安装方法很多，没几个成功的，可能是版本原因，所以我直接从Github上下一个 12345$ git clone git://github.com/mobz/elasticsearch-head.git$ cd elasticsearch-head$ npm install # 由于head基于nodejs$ grunt server# 浏览器访问 http://localhost:9100/ 这里可能遇见问题 “集群健康值: 未连接” 修改elasticsearch.yml文件 # 增加如下字段 http.cors.enabled: ``true http.cors.allow-origin: ``&quot;*&quot; 重启ES和HEAD就可以了 切换到Browser标签 单击某一个文档（doc），则会展示该文档的所有信息 Kinaba 点击 Download，选择你系统对应的文件下载，这里我选择的mac，下载完是.tar文件 下载完成后解压到你指定的目录 123$ tar -zxf kibana-5.2.2-darwin-x86_64.tar -C /usr/local/$ /usr/local/kibana-5.2.2-darwin-x86_64/bin/kibana浏览器访问http://localhost:5601/ 就可以查看安装成功了 配置 先在我们ELK都安装完了，接下来是如何关联在一起了 Logstash 配置 1234567891011121314151617181920212223242526272829$ cd /usr/local/logstash-5.2.2/config$ vim elasticsearche.conf #新建配置文件$ cat elasticsearche.confinput &#123; file &#123; path =&gt; "/myapp/storage/logs/lumen.log" # 日志文件目录 start_position =&gt; "beginning" #从文件开始处读写 &#125;&#125;filter &#123; #定义数据的格式 grok &#123; match =&gt; &#123; "message" =&gt;"%&#123;DATA:timestamp&#125;\|%&#123;IP:serverIp&#125;\|%&#123;IP:clientIp&#125;\|%&#123;DATA:logSource&#125;\|%&#123;DATA:userId&#125;\|%&#123;DATA:reqUrl&#125;\|%&#123;DATA:reqUri&#125;\|%&#123;DATA:refer&#125;\|%&#123;DATA:device&#125;\|%&#123;DATA:textDuring&#125;\|%&#123;DATA:duringTime:int&#125;\|\|" &#125; // 对应的日志格式为 /** 2015-05-07-16:03:04|10.4.29.158|120.131.74.116|WEB|11299073|http://quxue.renren.com/shareApp?isappinstalled=0&amp;userId=11299073&amp;from=groupmessage|/shareApp|null|Mozilla/5.0 (iPhone; CPU iPhone OS 8_2 like Mac OS X) AppleWebKit/600.1.4 (KHTML, like Gecko) Mobile/12D508 MicroMessenger/6.1.5 NetType/WIFI|duringTime|98|| */ &#125;&#125;output &#123; #将输出保存到elasticsearch，如果没有匹配到时间就不保存，因为日志里的网址参数有些带有换行, 注意网上有的配置写的是host，总会报错，查了下在某一版本改成了hosts if [timestamp] =~ /^\d&#123;4&#125;-\d&#123;2&#125;-\d&#123;2&#125;/ &#123; elasticsearch &#123; hosts =&gt; localhost&#125; &#125;&#125; 定义数据格式很重要，不然会匹配不出你的日志至于如何写，参考elastic/logstash 这个是定义好的 12$ /usr/local/logstash-5.2.2/bin/logstash -f /usr/local/logstash-5.2.2/config/elasticsearche.conf #以这个配置文件运行logstash ​ Kinaba 配置 第一次访问kibana会重定向到设置索引的页面,如果输入logstash-*就是匹配所有的索引，还可以指定日期，logstash的索引是按日期区分的，一个日期一个文件夹 create 之后点击Discover就可以查看分组的日志和实时日志。 参考文章：http://baidu.blog.51cto.com/71938/1676798]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Docker——初探]]></title>
      <url>%2F2017%2F03%2F24%2FDocker%E2%80%94%E2%80%94%E5%88%9D%E6%8E%A2%2F</url>
      <content type="text"><![CDATA[起因想要学习是我写这篇博文的原因，虽然我暂时在开发中用不到Docker，但是为了开阔视野我想也应该了解下，学习是没有坏处的 概念Docker解释有很多，这里我就不照搬了，否则我的这篇博文都是介绍了，大概解释是：Docker 使用的Google的go语言开发实现，现在是开源的，主要代码是Github 上进行维护，是操作系统层面的虚拟化技术 。 为什么用Docker 多数优点都是对应虚拟机而言 更高效的利用系统资源 更快的启动时间 一致的运行环境 这个我认为最重要，在开发，测试，生产保持环境一致，不会因为系统导致 “这段代码在我机器上没问题啊” 这类问题。 持续交付和部署 更轻松的迁移 Docker 可以在很多平台上运行，无论是物理机、虚拟机、公有云、私有云，甚至是笔记本，其运行结果是一致的。 更轻松的维护和扩展 基本概念 Docker 镜像 (Image) Docker 镜像是一个特殊的文件系统，是由一组文件系统组成，或者说，由多层文件系统联合组成。镜像构建时，会一层层构建，前一层是后一层的基础。每一层构建完就不会再发生改变，后一层上的任何改变只发生在自己这一层。 Docker 容器 (Container) 镜像（Image）和容器（Container）的关系，就像是面向对象程序设计中的类和实例一样，镜像是静态的定义，容器是镜像运行时的实体。容器可以被创建、启动、停止、删除、暂停等。 Docker 仓库 (Registry) 镜像构建完成后，可以很容易的在当前宿主上运行，但是，如果需要在其它服务器上使用这个镜像，我们就需要一个集中的存储、分发镜像的服务，Docker Registry 就是这样的服务。 我的理解是Docker Registry 就是一个Github，每个软件或者系统就是一个项目，项目有标签就是每个软件的版本。当然这里的Registry 也有公开服务和私有服务。 参考文章： Docker 从入门到实践 Docker背后的容器管理——Libcontainer深度解析 这个可以加深了解容器是什么。]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[Nginx反向代理和负载均衡]]></title>
      <url>%2F2017%2F03%2F23%2FNginx%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86%E5%92%8C%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%2F</url>
      <content type="text"><![CDATA[正向代理 明确知道要访问的网站 A服务器可以访问C，访客可以访问服务器A，不可以访问服务器C，A为代理服务器 反向代理 不知道所访问真实服务器 访客可以访问服务器A，服务器A无数据，服务器A从其他服务器中读取数据并且返回给访客 负载均衡 服务器压力过大会使服务器崩溃,通过负载均衡来分担服务器压力，通过反向代理来实现的 Nginx 负载均衡的实现 Nginx可以通过反向代理实现负载均衡，用户的访问首先会访问到Nginx服务器，然后Nginx选择压力较小的服务器，并且访问的是未崩溃的服务器。 upstream name 配置代理服务器 HTTP Upstream 模块 Upstream 模块是Nginx服务器的一个重要模块，Upstream模块实现在轮询和客户端IP之间实现后端的负载均衡 常用指令ip_hash, server, Upstream ip_hash：在负载均衡系统中，假如用户在某台服务器上登录，那么如果该用户第二次请求时候，因为负载均衡系统，每次请求都会重新定位到一个新服务器，显然不可以，可以采用Ip_hash指令解决这个问题，第二次请求会通过哈希算法自动定位到第一次登录的服务器。 server：server指令主要用于指定服务器的名称和参数，通过参数设置不同服务器的权重 upstream：主要是用于设置一组可以在proxy_pass和fastcgi_pass指令中使用代理服务器，默认负载均衡方式为轮询 其他负载均衡的方法 除了使用Nginx服务器实现外，还有很多方式，软件实现和硬件实现，软件分服务器软件、系统软件、应用软件，根据反向代理的中间相关。 负载均衡实现小结 硬件实现负载均衡：效率高，成本高 软件实现负载均衡：效率相对低，成本低（nginx） ​]]></content>
    </entry>

    
    <entry>
      <title><![CDATA[从零开始搭建HEXO]]></title>
      <url>%2F2017%2F03%2F21%2F%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E6%90%AD%E5%BB%BAHEXO%2F</url>
      <content type="text"><![CDATA[起因一直有搭建个人博客的想法，并几次都付诸行动，以前用过Wordpress, Typecho，最后都因为各种原因下线或者放弃了，其中各种插件的以及部署问题已经忙的焦头烂额，最近又一次燃起了搭建个人博客的想法，通过各种产品之间的比较，最后我选中了Hexo，选中它的最大原因是因为不需要数据库，而且对环境要求较少。 正文我使用Mac系统，安装Hexo时候的版本是hexo: 3.2.2，其他系统替换相应命令即可。 安装前准备虽然Hexo对环境要求较少，但是安装前还是需要一些准备的 Node.js Windows：nodejs官网安装 Mac：brew install node Linux：curl https://raw.github.com/creationix/nvm/master/install.sh | sh Git Windows：下载安装 git Mac： brew install git Linux：sudo apt-get install git Github：如果有就忽略，没有去注册个github 开始安装前面的准备完成就开始正式安装Hexo，在终端输入如下命令： 1$ npm install -g hexo-cli 安装完成输入： 12$ hexo -vhexo: 3.2.2 出现hexo版本就安装成功了。 建站输入如下命令， 项目目录名称： 123$ hexo init &lt;folder&gt;$ cd &lt;folder&gt;$ npm install 生成静态文件 1$ hexo g # 或者hexo generate 启动本地web服务 1$ hexo s # 或者hexo server 在浏览器访问http://localhost:4000，就可以看到博客了 常用命令 12$ hexo new "postName" #新建文章$ hexo new page "pageName" #新建页面 例如about /source/about/index.md Hexo 主题安装我使用的是Anatole这个主题，更多主题可以在官网主题选择，以下是主题安装方式： 12$ cd &lt;folder&gt;$ git clone https://github.com/Ben02/hexo-theme-Anatole theme/anatole 启用主题 在根目录的_config.yml配置中的theme属性，将其设置为anatole，主题所有的配置在:后都要有一个空格 更新主题 1234$ cd theme/anatole$ git pull$ hexo g #生成静态$ hexo s #启动本地web服务 访问http://localhost:4000，就可以看见新的主题了 Github Pages 设置GitHub Pages 本用于介绍托管在GitHub的项目，不过，由于他的空间免费稳定，可以用来用来做搭建一个博客 每个帐号只能有一个仓库来存放个人主页，而且仓库的名字必须是username/username.github.io，这是特殊的命名约定。你可以通过http://username.github.io 来访问你的个人主页。 这里特别提醒一下，需要注意的个人主页的网站内容是在master分支下的，而且只能在master分支。 申请方式可以建立其他的仓库一样，只要把以http://username.github.io来命名就可以了（username 即你的账户名）。 下面就开始部署本地的博客到github： 打开根目录的_config.yml，文件找到Deployment，配置如下 1234deploy: type: git repo: https://github.com/username/username.github.io.git branch: master 保存后执行如下命令 1234$ npm install hexo-deployer-git --save # 部署到远程需要安装的包$ hexo clean$ hexo generate$ hexo deploy # Hexo部署到远程 这时查看代码库就可以看到代码已经在github上了，访问http://username.github.io 就可以看到你的博客了 如何用自己的域名来访问博客在source目录下添加CNAME文件，操作步骤如下 12345$ cd source/$ vim CNAME # 输入你的域名在CNAME文件下$ hexo clean # 返回根目录执行$ hexo generate$ hexo deploy # Hexo部署到远程 添加解析 12记录类型 主机记录 解析线路(运营商) 记录值 CNAME www 默认 username.github.io 如果不生效添加 123记录类型 主机记录 解析线路(运营商) 记录值 A @ 默认 192.30.252.154 A @ 默认 192.30.252.153 访问你的域名就可以看到你的博客了。]]></content>
    </entry>

    
  
  
</search>
